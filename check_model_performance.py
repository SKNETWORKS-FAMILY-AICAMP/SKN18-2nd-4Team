#!/usr/bin/env python3
"""
ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
import logging
import joblib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_model_performance():
    """ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ í™•ì¸"""
    logger.info("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ í™•ì¸ ì‹œì‘")
    
    try:
        # ì €ì¥ëœ ëª¨ë¸ ê²°ê³¼ ë¡œë“œ
        model_results = joblib.load("outputs/model_results.pkl")
        
        print("ğŸ† ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼")
        print("=" * 60)
        
        # ëª¨ë¸ ì ìˆ˜ í™•ì¸
        if 'model_scores' in model_results:
            model_scores = model_results['model_scores']
            best_model_name = model_results.get('best_model_name', 'Unknown')
            
            print(f"ğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
            print(f"ğŸ“ˆ ìµœê³  ì ìˆ˜: {model_scores[best_model_name]:.4f}")
            print("\nğŸ“Š ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
            print("-" * 60)
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_scores = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)
            
            for i, (model_name, score) in enumerate(sorted_scores, 1):
                medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
                print(f"{medal} {i:2d}. {model_name:<20} : {score:.4f}")
        
        # ìµœì¢… í‰ê°€ ê²°ê³¼ í™•ì¸
        if 'final_results' in model_results:
            final_results = model_results['final_results']
            print(f"\nğŸ“‹ ìµœì¢… í‰ê°€ ê²°ê³¼ ({best_model_name}):")
            print("-" * 60)
            print(f"Accuracy  : {final_results.get('accuracy', 0):.4f}")
            print(f"Precision : {final_results.get('precision', 0):.4f}")
            print(f"Recall    : {final_results.get('recall', 0):.4f}")
            print(f"F1-Score  : {final_results.get('f1', 0):.4f}")
            print(f"AUC       : {final_results.get('auc', 0):.4f}")
        
        # ë³µí•© ì ìˆ˜ ê°€ì¤‘ì¹˜ í™•ì¸
        print(f"\nâš–ï¸ ë³µí•© ì ìˆ˜ ê°€ì¤‘ì¹˜:")
        print("-" * 60)
        print("AUC      : 40%")
        print("F1-Score : 30%")
        print("Precision: 20%")
        print("Recall   : 10%")
        print("=" * 60)
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì„±ëŠ¥ í™•ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_model_performance()
