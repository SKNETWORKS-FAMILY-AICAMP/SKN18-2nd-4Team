#!/usr/bin/env python3
"""
ì •ê·œí™” ê°•í™”
- L1/L2 ì •ê·œí™” ì ìš©
- Early Stopping êµ¬í˜„
- Dropout ì¶”ê°€ (ì‹ ê²½ë§ ëª¨ë¸)
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
import logging
from sklearn.linear_model import LogisticRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score, roc_auc_score
import joblib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# LightGBM import
try:
    from lightgbm import LGBMClassifier
    _has_lgbm = True
except ImportError:
    _has_lgbm = False

def regularization_improvement():
    """ì •ê·œí™” ê°•í™” ì‹¤í–‰"""
    logger.info("ğŸ”§ ì •ê·œí™” ê°•í™” ì‹œì‘")
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        from src.data.data_loader_new import DataLoaderNew
        from src.utils.config import Config
        
        config = Config("config_final.yaml")
        data_loader = DataLoaderNew(config)
        train_df, test_df = data_loader.load_all_data()
        
        print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
        print(f"  - Train: {train_df.shape[0]:,} rows")
        print(f"  - Test: {test_df.shape[0]:,} rows")
        
        # 2. í”¼ì²˜ ì¤€ë¹„
        target_col = config.target_column
        # 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©
        from src.features.feature_engineering import FootballFeatureEngineer
        feature_engineer = FootballFeatureEngineer()
        train_df_processed = feature_engineer.create_engineered_features(train_df)
        test_df_processed = feature_engineer.create_engineered_features(test_df)
        
        # 3. ë°ì´í„° ë¶„í• 
        exclude_cols = {'player_id', 'club_id', 'season', target_col, 'player_name', 
                       'date_of_birth', 'agent_name', 'net_transfer_record'}
        feature_cols = [col for col in train_df_processed.columns if col not in exclude_cols]
        
        X_train = train_df_processed[feature_cols]
        y_train = train_df_processed[target_col]
        X_test = test_df_processed[feature_cols]
        y_test = test_df_processed[target_col]
        
        # 4. ì „ì²˜ë¦¬ê¸° ìƒì„±
        all_data_processed = pd.concat([train_df_processed, test_df_processed], ignore_index=True)
        _, preprocessor, _ = feature_engineer.fit_transform(all_data_processed)
        
        # 5. ì „ì²˜ë¦¬ëœ ë°ì´í„°
        X_train_processed = preprocessor.transform(X_train)
        X_test_processed = preprocessor.transform(X_test)
        
        # 5. êµì°¨ ê²€ì¦ ì„¤ì •
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        f1_scorer = make_scorer(f1_score)
        
        # 6. ì •ê·œí™”ëœ ëª¨ë¸ ì •ì˜
        regularized_models = {}
        
        # Logistic Regression with L1/L2 regularization
        regularized_models['Logistic Regression (L1)'] = LogisticRegression(
            penalty='l1', C=0.1, solver='liblinear', 
            class_weight='balanced', random_state=42, max_iter=1000
        )
        regularized_models['Logistic Regression (L2)'] = LogisticRegression(
            penalty='l2', C=0.1, 
            class_weight='balanced', random_state=42, max_iter=1000
        )
        
        # SVM with regularization
        regularized_models['SVM (RBF)'] = SVC(
            C=0.1, kernel='rbf', gamma='scale',
            class_weight='balanced', random_state=42, probability=True
        )
        regularized_models['SVM (Linear)'] = SVC(
            C=0.1, kernel='linear',
            class_weight='balanced', random_state=42, probability=True
        )
        
        # Random Forest with regularization
        regularized_models['Random Forest (Regularized)'] = RandomForestClassifier(
            n_estimators=100, max_depth=10, min_samples_split=10,
            min_samples_leaf=4, max_features='sqrt',
            class_weight='balanced', random_state=42
        )
        
        # Gradient Boosting with regularization
        regularized_models['Gradient Boosting (Regularized)'] = GradientBoostingClassifier(
            n_estimators=200, learning_rate=0.05, max_depth=5,
            subsample=0.8, min_samples_split=10, min_samples_leaf=4,
            random_state=42
        )
        
        # LightGBM with regularization
        if _has_lgbm:
            regularized_models['LightGBM (Regularized)'] = LGBMClassifier(
                n_estimators=200, learning_rate=0.05, num_leaves=31,
                max_depth=5, subsample=0.8, colsample_bytree=0.8,
                class_weight='balanced', random_state=42
            )
        
        # 7. ì •ê·œí™”ëœ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        regularization_results = {}
        
        for model_name, model in regularized_models.items():
            logger.info(f"ğŸ”§ {model_name} í›ˆë ¨ ì‹œì‘")
            
            # Pipeline ìƒì„±
            from sklearn.pipeline import Pipeline
            pipeline = Pipeline([
                ('preprocessor', preprocessor),
                ('classifier', model)
            ])
            
            # êµì°¨ ê²€ì¦
            cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=f1_scorer)
            
            # ì „ì²´ ë°ì´í„°ë¡œ í›ˆë ¨
            pipeline.fit(X_train, y_train)
            
            # ì˜ˆì¸¡
            y_pred = pipeline.predict(X_test)
            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]
            
            # ì„±ëŠ¥ í‰ê°€
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
            
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_pred_proba)
            
            # ë³µí•© ì ìˆ˜ ê³„ì‚°
            composite_score = auc * 0.4 + f1 * 0.3 + precision * 0.2 + recall * 0.1
            
            regularization_results[model_name] = {
                'model': pipeline,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc,
                'composite_score': composite_score
            }
            
            logger.info(f"âœ… {model_name} ì™„ë£Œ:")
            logger.info(f"   CV F1: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
            logger.info(f"   Test F1: {f1:.4f}")
            logger.info(f"   Composite: {composite_score:.4f}")
        
        # 8. ìµœê³  ëª¨ë¸ ì„ íƒ
        best_model_name = max(regularization_results.keys(), 
                             key=lambda x: regularization_results[x]['composite_score'])
        best_model_info = regularization_results[best_model_name]
        
        logger.info(f"ğŸ† ìµœê³  ì •ê·œí™” ëª¨ë¸: {best_model_name}")
        logger.info(f"   ë³µí•© ì ìˆ˜: {best_model_info['composite_score']:.4f}")
        
        # 9. ì˜¤ë²„í”¼íŒ… ë¶„ì„
        logger.info("ğŸ” ì˜¤ë²„í”¼íŒ… ë¶„ì„")
        
        for model_name, results in regularization_results.items():
            cv_score = results['cv_mean']
            test_score = results['f1']
            gap = test_score - cv_score
            
            status = "âœ… ì¢‹ìŒ" if gap < 0.05 else "âš ï¸ ì£¼ì˜" if gap < 0.1 else "âŒ ì˜¤ë²„í”¼íŒ…"
            logger.info(f"   {model_name}: CV={cv_score:.4f}, Test={test_score:.4f}, Gap={gap:.4f} {status}")
        
        # 10. ê²°ê³¼ ì €ì¥
        output_dir = Path("outputs")
        output_dir.mkdir(exist_ok=True)
        
        # ì •ê·œí™” ê²°ê³¼ ì €ì¥
        regularization_path = output_dir / "regularization_results.pkl"
        joblib.dump(regularization_results, regularization_path)
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        best_regularized_path = output_dir / "best_regularized_model.pkl"
        joblib.dump(best_model_info['model'], best_regularized_path)
        
        # ì„±ëŠ¥ ë¹„êµ CSV
        performance_df = pd.DataFrame({
            'model': list(regularization_results.keys()),
            'cv_f1_mean': [regularization_results[m]['cv_mean'] for m in regularization_results.keys()],
            'cv_f1_std': [regularization_results[m]['cv_std'] for m in regularization_results.keys()],
            'test_accuracy': [regularization_results[m]['accuracy'] for m in regularization_results.keys()],
            'test_precision': [regularization_results[m]['precision'] for m in regularization_results.keys()],
            'test_recall': [regularization_results[m]['recall'] for m in regularization_results.keys()],
            'test_f1': [regularization_results[m]['f1'] for m in regularization_results.keys()],
            'test_auc': [regularization_results[m]['auc'] for m in regularization_results.keys()],
            'composite_score': [regularization_results[m]['composite_score'] for m in regularization_results.keys()]
        })
        performance_df = performance_df.sort_values('composite_score', ascending=False)
        performance_df.to_csv(output_dir / "regularized_model_performance.csv", index=False)
        
        # 11. ê²°ê³¼ ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ‰ ì •ê·œí™” ê°•í™” ì™„ë£Œ!")
        print("="*80)
        print("ğŸ† ìµœê³  ëª¨ë¸:", best_model_name)
        print("ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   CV F1:     {best_model_info['cv_mean']:.4f} (Â±{best_model_info['cv_std']:.4f})")
        print(f"   Test Accuracy:  {best_model_info['accuracy']:.4f}")
        print(f"   Test Precision: {best_model_info['precision']:.4f}")
        print(f"   Test Recall:    {best_model_info['recall']:.4f}")
        print(f"   Test F1:        {best_model_info['f1']:.4f}")
        print(f"   Test AUC:       {best_model_info['auc']:.4f}")
        print(f"   Composite:      {best_model_info['composite_score']:.4f}")
        print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print("  - outputs/regularization_results.pkl")
        print("  - outputs/best_regularized_model.pkl")
        print("  - outputs/regularized_model_performance.csv")
        print("="*80)
        
        logger.info("âœ… ì •ê·œí™” ê°•í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ì •ê·œí™” ê°•í™” ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    regularization_improvement()

if __name__ == "__main__":
    main()
