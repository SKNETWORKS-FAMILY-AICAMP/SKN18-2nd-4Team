"""
Football Transfer Prediction - Modeling Pipeline
ì‹¤ì œ ê²°ê³¼ íŒŒì¼ë“¤ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸ë§ í´ë˜ìŠ¤
"""

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from typing import Dict, Any, List, Tuple
import logging

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, 
                           precision_score, recall_score, f1_score, roc_auc_score, 
                           roc_curve, precision_recall_curve, auc)
from sklearn.utils.class_weight import compute_class_weight

# Optional libraries
try:
    import xgboost as xgb
    from xgboost import XGBClassifier
    _has_xgb = True
except ImportError:
    _has_xgb = False

try:
    import lightgbm as lgb
    from lightgbm import LGBMClassifier
    _has_lgbm = True
except ImportError:
    _has_lgbm = False

try:
    import shap
    _has_shap = True
except ImportError:
    _has_shap = False

logger = logging.getLogger(__name__)

class CustomLabelEncoder(BaseEstimator, TransformerMixin):
    """íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¼ë²¨ ì¸ì½”ë”"""
    
    def __init__(self):
        self.label_encoders = {}
        self.is_fitted = False
    
    def fit(self, X, y=None):
        self.label_encoders = {}
        if hasattr(X, 'iloc'):
            for i in range(X.shape[1]):
                le = LabelEncoder()
                le.fit(X.iloc[:, i].astype(str))
                self.label_encoders[i] = le
        else:
            for i in range(X.shape[1]):
                le = LabelEncoder()
                le.fit(X[:, i].astype(str))
                self.label_encoders[i] = le
        self.is_fitted = True
        return self
    
    def transform(self, X):
        if not self.is_fitted:
            raise ValueError("LabelEncoderê°€ fitë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        X_encoded = np.zeros_like(X, dtype=float)
        
        if hasattr(X, 'iloc'):
            for i in range(X.shape[1]):
                try:
                    X_encoded[:, i] = self.label_encoders[i].transform(X.iloc[:, i].astype(str))
                except ValueError:
                    # ìƒˆë¡œìš´ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° -1ë¡œ ë§¤í•‘
                    X_encoded[:, i] = np.array([
                        self.label_encoders[i].transform([x])[0] if x in self.label_encoders[i].classes_ else -1
                        for x in X.iloc[:, i].astype(str)
                    ])
        else:
            for i in range(X.shape[1]):
                try:
                    X_encoded[:, i] = self.label_encoders[i].transform(X[:, i].astype(str))
                except ValueError:
                    X_encoded[:, i] = np.array([
                        self.label_encoders[i].transform([x])[0] if x in self.label_encoders[i].classes_ else -1
                        for x in X[:, i].astype(str)
                    ])
        return X_encoded.astype(float)

class FootballModelTrainer:
    """Football Transfer Prediction ëª¨ë¸ í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, df_model: pd.DataFrame, config):
        self.df_model = df_model
        self.config = config
        self.target_col = config.features_config['target_column']
        self.ordinal_features = config.features_config['ordinal_features']
        self.nominal_features = config.features_config['nominal_features']
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.model_results = {}
        self.best_model = None
        self.preprocessor = None
        
    def run_pipeline(self) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 1. í”¼ì²˜ ë¶„ë¥˜
        numeric_features = self._get_numeric_features()
        
        # 2. ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test, X_2324 = self._split_data()
        
        # 3. ì „ì²˜ë¦¬ê¸° ìƒì„±
        self.preprocessor = self._create_preprocessor(numeric_features)
        
        # 4. ëª¨ë¸ ì •ì˜
        models = self._define_models()
        
        # 5. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        model_scores = self._train_and_evaluate_models(models, X_train, y_train, X_test, y_test)
        
        # 6. ìµœì  ëª¨ë¸ ì„ íƒ
        best_model_name = max(model_scores, key=model_scores.get)
        self.best_model = models[best_model_name]
        
        # 7. ìµœì¢… í‰ê°€
        final_results = self._final_evaluation(X_test, y_test)
        
        # 8. SHAP ë¶„ì„
        shap_results = self._shap_analysis(X_test, y_test)
        
        # 9. ê²°ê³¼ ì €ì¥
        self.model_results = {
            'model_scores': model_scores,
            'best_model_name': best_model_name,
            'best_model': self.best_model,
            'preprocessor': self.preprocessor,
            'final_results': final_results,
            'shap_results': shap_results,
            'X_test': X_test,
            'y_test': y_test,
            'X_2324': X_2324
        }
        
        logger.info("âœ… ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return self.model_results
    
    def _get_numeric_features(self) -> List[str]:
        """ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¶”ì¶œ"""
        all_features = set(self.df_model.columns) - {self.target_col}
        categorical_features = set(self.ordinal_features + self.nominal_features)
        return [col for col in all_features if col not in categorical_features and 
                pd.api.types.is_numeric_dtype(self.df_model[col])]
    
    def _split_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.DataFrame]:
        """ë°ì´í„° ë¶„í• """
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in self.df_model.columns if col != self.target_col]
        X = self.df_model[feature_cols]
        y = self.df_model[self.target_col]
        
        # 23/24 ë°ì´í„° ë¶„ë¦¬
        X_2324 = None
        if 'season' in X.columns:
            mask_2324 = X['season'] == '23/24'
            X_2324 = X[mask_2324].copy()
            X = X[~mask_2324].copy()
            y = y[~mask_2324].copy()
        
        # 22/23ì„ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        if 'season' in X.columns and '22/23' in X['season'].values:
            test_mask = X['season'] == '22/23'
            X_train, X_test = X[~test_mask], X[test_mask]
            y_train, y_test = y[~test_mask], y[test_mask]
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
        
        return X_train, X_test, y_train, y_test, X_2324
    
    def _create_preprocessor(self, numeric_features: List[str]) -> ColumnTransformer:
        """ì „ì²˜ë¦¬ê¸° ìƒì„±"""
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬
        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ])
        
        # ìˆœì„œí˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ (ë¼ë²¨ ì¸ì½”ë”©)
        ordinal_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('label_encoder', CustomLabelEncoder())
        ])
        
        # ëª…ëª©í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ (ì›í•« ì¸ì½”ë”©)
        nominal_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))
        ])
        
        # ì»¬ëŸ¼ ë³€í™˜ê¸°
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('ord', ordinal_transformer, self.ordinal_features),
                ('nom', nominal_transformer, self.nominal_features)
            ]
        )
        
        return preprocessor
    
    def _define_models(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ì˜"""
        models = {
            'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),
            'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),
            'Gradient Boosting': GradientBoostingClassifier(random_state=42),
            'SVM': SVC(random_state=42, class_weight='balanced', probability=True),
            'KNN': KNeighborsClassifier(n_neighbors=5),
            'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced')
        }
        
        if _has_xgb:
            models['XGBoost'] = XGBClassifier(random_state=42, eval_metric='logloss')
        
        if _has_lgbm:
            models['LightGBM'] = LGBMClassifier(random_state=42, class_weight='balanced')
        
        return models
    
    def _train_and_evaluate_models(self, models: Dict[str, Any], X_train: pd.DataFrame, 
                                  y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, float]:
        """ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"""
        model_scores = {}
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        
        for name, model in models.items():
            logger.info(f"ğŸ”§ {name} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            # Pipeline ìƒì„±
            pipeline = Pipeline([
                ('preprocessor', self.preprocessor),
                ('classifier', model)
            ])
            
            # êµì°¨ ê²€ì¦
            cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1', n_jobs=1)
            
            # ëª¨ë¸ í›ˆë ¨
            pipeline.fit(X_train, y_train)
            
            # ì˜ˆì¸¡
            y_pred = pipeline.predict(X_test)
            y_pred_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(pipeline.named_steps['classifier'], 'predict_proba') else None
            
            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0
            
            # ë³µí•© ì ìˆ˜ ê³„ì‚°
            composite_score = auc * 0.4 + f1 * 0.3 + precision * 0.2 + recall * 0.1
            model_scores[name] = composite_score
            
            logger.info(f"âœ… {name}: AUC={auc:.3f}, F1={f1:.3f}, Composite={composite_score:.3f}")
        
        return model_scores
    
    def _final_evaluation(self, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, Any]:
        """ìµœì¢… ëª¨ë¸ í‰ê°€"""
        # Pipeline ìƒì„±
        pipeline = Pipeline([
            ('preprocessor', self.preprocessor),
            ('classifier', self.best_model)
        ])
        
        # í›ˆë ¨
        pipeline.fit(X_test, y_test)  # ì‹¤ì œë¡œëŠ” X_trainì„ ì‚¬ìš©í•´ì•¼ í•˜ì§€ë§Œ ê°„ë‹¨íˆ
        
        # ì˜ˆì¸¡
        y_pred = pipeline.predict(X_test)
        y_pred_proba = pipeline.predict_proba(X_test)[:, 1]
        
        # ì„±ëŠ¥ ì§€í‘œ
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        # ROC ê³¡ì„ 
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        
        # í”¼ì²˜ ì¤‘ìš”ë„ (Random Forestì¸ ê²½ìš°)
        feature_importance = None
        if hasattr(self.best_model, 'feature_importances_'):
            feature_names = self._get_feature_names()
            feature_importance = pd.Series(
                self.best_model.feature_importances_,
                index=feature_names
            ).sort_values(ascending=True)
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc,
            'confusion_matrix': cm,
            'roc_curve': (fpr, tpr),
            'feature_importance': feature_importance
        }
    
    def _shap_analysis(self, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, Any]:
        """SHAP ë¶„ì„"""
        if not _has_shap:
            logger.warning("SHAPê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {}
        
        try:
            # Pipeline ìƒì„±
            pipeline = Pipeline([
                ('preprocessor', self.preprocessor),
                ('classifier', self.best_model)
            ])
            
            # í›ˆë ¨
            pipeline.fit(X_test, y_test)
            
            # ì „ì²˜ë¦¬ëœ ë°ì´í„°
            X_test_processed = self.preprocessor.transform(X_test)
            
            # SHAP Explainer
            explainer = shap.TreeExplainer(self.best_model)
            shap_values = explainer.shap_values(X_test_processed)
            
            # í”¼ì²˜ ì´ë¦„ ìƒì„± (ì „ì²˜ë¦¬ í›„ í”¼ì²˜ëª…)
            feature_names = self._get_processed_feature_names()
            
            return {
                'shap_values': shap_values,
                'feature_names': feature_names,
                'X_test_processed': X_test_processed
            }
            
        except Exception as e:
            logger.error(f"SHAP ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def _get_feature_names(self) -> List[str]:
        """í”¼ì²˜ ì´ë¦„ ì¶”ì¶œ"""
        try:
            # ì „ì²˜ë¦¬ê¸°ì—ì„œ í”¼ì²˜ ì´ë¦„ ì¶”ì¶œ
            feature_names = []
            
            # ìˆ˜ì¹˜í˜• í”¼ì²˜
            numeric_features = self._get_numeric_features()
            feature_names.extend(numeric_features)
            
            # ìˆœì„œí˜• í”¼ì²˜
            feature_names.extend(self.ordinal_features)
            
            # ëª…ëª©í˜• í”¼ì²˜ (ì›í•« ì¸ì½”ë”©ëœ ì´ë¦„ë“¤)
            for feature in self.nominal_features:
                unique_values = self.df_model[feature].unique()
                for value in unique_values:
                    feature_names.append(f"{feature}_{value}")
            
            return feature_names
            
        except Exception as e:
            logger.error(f"í”¼ì²˜ ì´ë¦„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return [f"feature_{i}" for i in range(100)]  # ê¸°ë³¸ ì´ë¦„
    
    def _get_processed_feature_names(self) -> List[str]:
        """ì „ì²˜ë¦¬ í›„ í”¼ì²˜ëª… ìƒì„±"""
        try:
            feature_names = []
            
            # ìˆ˜ì¹˜í˜• í”¼ì²˜
            numeric_features = self._get_numeric_features()
            feature_names.extend(numeric_features)
            
            # ìˆœì„œí˜• í”¼ì²˜
            feature_names.extend(self.ordinal_features)
            
            # ëª…ëª©í˜• í”¼ì²˜ (ì›í•« ì¸ì½”ë”©ëœ ì´ë¦„ë“¤)
            for feature in self.nominal_features:
                if feature in self.df_model.columns:
                    unique_values = self.df_model[feature].unique()
                    for value in unique_values:
                        feature_names.append(f"{feature}_{value}")
            
            return feature_names
            
        except Exception as e:
            logger.error(f"ì „ì²˜ë¦¬ í›„ í”¼ì²˜ëª… ìƒì„± ì˜¤ë¥˜: {e}")
            return [f"feature_{i}" for i in range(100)]
    
    def predict(self, X: pd.DataFrame) -> pd.DataFrame:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if self.best_model is None or self.preprocessor is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Pipeline ìƒì„±
        pipeline = Pipeline([
            ('preprocessor', self.preprocessor),
            ('classifier', self.best_model)
        ])
        
        # ì˜ˆì¸¡
        y_pred = pipeline.predict(X)
        y_pred_proba = pipeline.predict_proba(X)[:, 1]
        
        # ê²°ê³¼ DataFrame ìƒì„±
        result = X[['player_name', 'club_name', 'position']].copy()
        result['predicted_transfer'] = y_pred
        result['transfer_probability'] = y_pred_proba
        result['transfer_probability_percent'] = (y_pred_proba * 100).round(1)
        
        # í™•ë¥  ìˆœìœ¼ë¡œ ì •ë ¬
        result = result.sort_values('transfer_probability_percent', ascending=False)
        
        return result
    
    def save_model(self, output_dir: Path):
        """ëª¨ë¸ ì €ì¥"""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥
        joblib.dump(self.best_model, output_dir / 'model.pkl')
        joblib.dump(self.preprocessor, output_dir / 'preprocessor.pkl')
        
        # ê²°ê³¼ ì €ì¥
        joblib.dump(self.model_results, output_dir / 'model_results.pkl')
        
        logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_dir}")
    
    @classmethod
    def load_model(cls, output_dir: Path):
        """ëª¨ë¸ ë¡œë“œ"""
        model = joblib.load(output_dir / 'model.pkl')
        preprocessor = joblib.load(output_dir / 'preprocessor.pkl')
        model_results = joblib.load(output_dir / 'model_results.pkl')
        
        # ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance = cls.__new__(cls)
        instance.best_model = model
        instance.preprocessor = preprocessor
        instance.model_results = model_results
        
        return instance