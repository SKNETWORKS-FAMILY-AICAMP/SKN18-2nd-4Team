{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9540a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (í•„ìˆ˜) ì´ ì…€/íŒŒì¼ì—ì„œ ì§ì ‘ ì‹¤í–‰í•œë‹¤ë©´ í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from pathlib import Path                 # íŒŒì¼/ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ê°ì²´ì§€í–¥ì ìœ¼ë¡œ ë‹¤ë£¨ê¸° ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from typing import List                  # íƒ€ì… íŒíŠ¸ìš© List\n",
    "import numpy as np                       # ìˆ˜ì¹˜ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬(ì•„ë˜ì—ì„œ np.number ë“± dtype íŒë³„ì— ì‚¬ìš©)\n",
    "import pandas as pd                      # ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# ============================================================================\n",
    "# ì…€ 2: Football ë°ì´í„° EDA - í†µí•© ë¶„ì„ (ê° í…Œì´ë¸”ë³„ë¡œ ëª¨ë“  ë¶„ì„ ìˆ˜í–‰)\n",
    "# ============================================================================\n",
    "\n",
    "def _project_root() -> Path:\n",
    "    cwd = Path.cwd()                                                         # í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬ë¥¼ Path ê°ì²´ë¡œ íšë“\n",
    "    if (cwd.parents / \"data\" / \"raw\").exists():                                      # í˜„ì¬ í´ë” ì•ˆì— data/raw í´ë”ê°€ ì¡´ì¬í•˜ë©´(í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ íŒë‹¨)\n",
    "        return cwd.parents                                                            # ê·¸ í˜„ì¬ ê²½ë¡œë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë°˜í™˜           # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì§€ì •í•œ ì ˆëŒ€ ê²½ë¡œë¥¼ ë£¨íŠ¸ë¡œ ì‚¬ìš©(Windows ê²½ë¡œëŠ” r'' ê¶Œì¥)\n",
    "\n",
    "def _memory_mb(df: pd.DataFrame) -> float:\n",
    "    return float(df.memory_usage(deep=True).sum() / 1024**2)                 # DataFrame ì „ì²´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(byte)ì„ MBë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜(deep=True: ê°ì²´ ì—´ê¹Œì§€ ì •í™• ê³„ì‚°)\n",
    "\n",
    "def _analyze_data_leakage_risks(df: pd.DataFrame, table_name: str) -> List[str]:\n",
    "    \"\"\"ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ìš”ì†Œë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"                              # í•¨ìˆ˜ ì„¤ëª…: EDA ì¤‘ 'ëˆ„ìˆ˜ ìœ„í—˜' í›„ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë¦¬í¬íŠ¸\n",
    "    risks = []                                                               # ëˆ„ìˆ˜ ìœ„í—˜ ë©”ì‹œì§€ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    \n",
    "    # 1. ë¯¸ë˜ ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„± (ë‚ ì§œ ì»¬ëŸ¼ ë¶„ì„)\n",
    "    date_cols = [col for col in df.columns                                   # ëª¨ë“  ì»¬ëŸ¼ëª…ì„ í›‘ì–´ë³´ë©°\n",
    "                 if any(keyword in col.lower()                               # ì†Œë¬¸ìí™”í•œ ì´ë¦„ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´\n",
    "                        for keyword in ['date', 'time', 'at', 'created', 'updated'])]\n",
    "    if date_cols:                                                             # ë‚ ì§œ/ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´\n",
    "        risks.append(f\"ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ ì¡´ì¬: {date_cols} - ë¯¸ë˜ ì •ë³´ ëˆ„ìˆ˜ ìœ„í—˜\")  # ë¯¸ë˜ ì‹œì  ì •ë³´ê°€ í¬í•¨ë  ê°€ëŠ¥ì„± ê²½ê³ (ë¦¬ë“œë¯¸ì„± í…ìŠ¤íŠ¸)\n",
    "\n",
    "    # 2. ê³ ìœ ê°’ ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ì€ ì»¬ëŸ¼ (ì‹ë³„ì ê°€ëŠ¥ì„±)\n",
    "    for col in df.columns:                                                    # ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´\n",
    "        if df[col].dtype == 'object':                                         # object(ë¬¸ìì—´/í˜¼í•©í˜•) íƒ€ì…ì¸ ê²½ìš°\n",
    "            unique_ratio = df[col].nunique() / len(df)                        # ìœ ë‹ˆí¬í•œ ê°’ì˜ ê°œìˆ˜ ë¹„ìœ¨(ë ˆì½”ë“œ ìˆ˜ë¡œ ë‚˜ëˆ”)\n",
    "            if unique_ratio > 0.95:                                           # ìœ ë‹ˆí¬ ë¹„ìœ¨ì´ 95% ì´ˆê³¼ â†’ ê±°ì˜ ì‹ë³„ì(ê³ ìœ í‚¤)ì¼ ê°€ëŠ¥ì„±\n",
    "                risks.append(f\"ê³ ìœ ê°’ ë¹„ìœ¨ ë†’ìŒ ({unique_ratio:.2%}): {col} - ì‹ë³„ì ê°€ëŠ¥ì„±\")\n",
    "\n",
    "    # 3. ê²°ì¸¡ê°’ íŒ¨í„´ ë¶„ì„\n",
    "    missing_pattern = df.isnull().sum()                                       # ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜ ì‹œë¦¬ì¦ˆ\n",
    "    if missing_pattern.sum():                                                 # ì „ì²´ ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ ì´ìƒì´ë©´\n",
    "        high_missing_cols = missing_pattern[missing_pattern > len(df) * 0.5]  # ê²°ì¸¡ë¥  50% ì´ˆê³¼ ì»¬ëŸ¼ë§Œ í•„í„°ë§\n",
    "        high_missing_cols = high_missing_cols.index.tolist()                  # ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        if high_missing_cols:                                                 # í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´\n",
    "            risks.append(f\"ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼: {high_missing_cols} - ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ\")  # í’ˆì§ˆ ì´ìŠˆ ê²½ê³  ì¶”ê°€\n",
    "    \n",
    "    return risks                                                              # ëˆ„ìˆ˜ ìœ„í—˜ ëª©ë¡ ë°˜í™˜\n",
    "\n",
    "# ì„¤ì •\n",
    "PROJECT_ROOT = _project_root()                                                # ìœ„ì—ì„œ ì •ì˜í•œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ê³„ì‚°(ë™ì /ê³ ì • ë¶„ê¸°)\n",
    "DATA_CURATED_DIR = PROJECT_ROOT / \"data\" / \"curated\"                          # curated CSVë“¤ì´ ëª¨ì—¬ ìˆëŠ” ë””ë ‰í„°ë¦¬ ê²½ë¡œ ìƒì„±(Path ì—°ì‚°ìë¡œ ê²°í•©)\n",
    "NROWS = None                                                                  # CSV ë¡œë”©ì‹œ ì½ì„ ìµœëŒ€ í–‰ ìˆ˜(None=ì „ì²´, ëŒ€ìš©ëŸ‰ì´ë©´ 1_000_000 ë“±ìœ¼ë¡œ ìƒ˜í”Œë§)\n",
    "MAX_UNIQUE = 25                                                               # ì €ì¹´ë””ë„ë¦¬í‹° íŒë‹¨ ê¸°ì¤€(ìœ ë‹ˆí¬ ê°œìˆ˜ê°€ 25 ì´í•˜ë©´ Low-cardinalë¡œ ê°„ì£¼)\n",
    "\n",
    "# CSV íŒŒì¼ ìë™ íƒìƒ‰\n",
    "csv_map = {p.stem: p for p in sorted(DATA_CURATED_DIR.glob(\"*.csv\"))}         # data/curated í´ë”ì—ì„œ *.csv íŒŒì¼ì„ ì°¾ì•„ {íŒŒì¼ì´ë¦„(í™•ì¥ìì œì™¸): Path} ë§¤í•‘ êµ¬ì„±\n",
    "\n",
    "print(\"=\" * 80)                                                               # êµ¬ë¶„ì„  ì¶œë ¥(ê°€ë…ì„±)\n",
    "print(\"ğŸ“Š FOOTBALL ë°ì´í„° EDA - í†µí•© ë¶„ì„ ê²°ê³¼\")                                 # ì œëª© ì¶œë ¥\n",
    "print(\"=\" * 80)                                                               # êµ¬ë¶„ì„ \n",
    "\n",
    "# 1. ë°œê²¬ëœ íŒŒì¼ ëª©ë¡\n",
    "print(\"\\nğŸ“ ë°œê²¬ëœ CSV íŒŒì¼ ëª©ë¡:\")                                            # ì„¹ì…˜ ì œëª©\n",
    "print(\"-\" * 50)                                                               # ì†Œì œëª© êµ¬ë¶„ì„ \n",
    "if not csv_map:                                                               # ì°¾ì€ CSVê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´\n",
    "    print(\"âŒ data/curated ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")                           # ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥\n",
    "else:\n",
    "    for i, (name, path) in enumerate(csv_map.items(), 1):                     # ë°œê²¬ëœ CSVë“¤ì„ ì¸ë±ìŠ¤ì™€ í•¨ê»˜ ìˆœíšŒ\n",
    "        print(f\"{i:2d}. {name:<20} -> {path}\")                                # ë²ˆí˜¸, íŒŒì¼ ìŠ¤í…œ, ì „ì²´ ê²½ë¡œ ì¶œë ¥(ì •ë ¬ ì„œì‹ ì ìš©)\n",
    "\n",
    "# 2. ê° í…Œì´ë¸”ë³„ í†µí•© ë¶„ì„ (ìƒì„¸ë¶„ì„ + ì €ì¹´ë””ë„ë¦¬í‹° + ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜)\n",
    "print(\"\\n\" + \"=\" * 80)                                                        # í° êµ¬ë¶„ì„ (ì¤„ë°”ê¿ˆ + ì¤„ê¸‹ê¸°)\n",
    "print(\"ğŸ“‹ í…Œì´ë¸”ë³„ í†µí•© ë¶„ì„\")                                               # ì„¹ì…˜ ì œëª©\n",
    "print(\"=\" * 80)                                                               # êµ¬ë¶„ì„ \n",
    "\n",
    "all_tables_info = {}                                                          # í…Œì´ë¸”ë³„ ìš”ì•½ ì •ë³´ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬(í‚¤: í…Œì´ë¸”ëª…, ê°’: ìš”ì•½ dict)\n",
    "data_leakage_risks = {}                                                       # í…Œì´ë¸”ë³„ ëˆ„ìˆ˜ ìœ„í—˜ ëª©ë¡ ì €ì¥ ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "for name, path in csv_map.items():                                            # ê° CSV(=ê° í…Œì´ë¸”)ë§ˆë‹¤ ë°˜ë³µ\n",
    "    try:\n",
    "        print(f\"\\n{'='*80}\")                                                  # í…Œì´ë¸”ë³„ ì‹œì‘ êµ¬ë¶„ì„ \n",
    "        print(f\"ğŸ” [{name.upper()}] í…Œì´ë¸” í†µí•© ë¶„ì„\")                          # í˜„ì¬ ë¶„ì„ ì¤‘ì¸ í…Œì´ë¸” ì´ë¦„ì„ ëŒ€ë¬¸ìë¡œ í‘œì‹œ\n",
    "        print(f\"{'='*80}\")                                                    # êµ¬ë¶„ì„ \n",
    "        \n",
    "        df = pd.read_csv(path, nrows=NROWS, low_memory=True)                  # CSV ë¡œë”©(ëŒ€ìš©ëŸ‰ ëŒ€ë¹„ low_memory=True: dtype ì¶”ë¡ ì„ ì§€ì—°/ë¶€ë¶„í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "\n",
    "        # ========================================\n",
    "        # 2. í…Œì´ë¸” ìƒì„¸ ë¶„ì„\n",
    "        # ========================================\n",
    "        print(f\"\\nğŸ“Š 2. í…Œì´ë¸” ìƒì„¸ ë¶„ì„\")                                      # ì†Œì œëª©\n",
    "        print(\"-\" * 50)                                                       # êµ¬ë¶„ì„ \n",
    "        \n",
    "        # ê¸°ë³¸ ì •ë³´\n",
    "        info = {                                                              \n",
    "            'rows': len(df),                                                  # í–‰ ìˆ˜\n",
    "            'cols': df.shape[1],                                              # ì—´ ìˆ˜\n",
    "            'memory_mb': _memory_mb(df),                                      # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(MB)\n",
    "            'missing_total': int(df.isnull().sum().sum()),                    # ì „ì²´ ê²°ì¸¡ì¹˜ ì´í•©(ì •ìˆ˜)\n",
    "            'missing_rate': float(df.isnull().sum().sum() / (len(df) * len(df.columns))), # ì „ì²´ ê²°ì¸¡ ë¹„ìœ¨(ê²°ì¸¡ ì´í•© / ì „ì²´ ì…€ ê°œìˆ˜)\n",
    "            'numeric_cols': len(df.select_dtypes(include=[np.number]).columns),            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê°œìˆ˜(np.number ê¸°ë°˜)\n",
    "            'categorical_cols': len(df.select_dtypes(include=['object', 'category']).columns),  # ë²”ì£¼í˜• ì»¬ëŸ¼ ê°œìˆ˜(object/category)\n",
    "            'date_cols': [col for col in df.columns                           # ë‚ ì§œ/ì‹œê°„ í›„ë³´ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸(í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ íƒì§€)\n",
    "                          if any(keyword in col.lower() for keyword in ['date', 'time', 'at'])],\n",
    "            'id_cols': [col for col in df.columns                             # ì‹ë³„ì í›„ë³´ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸(í‚¤ì›Œë“œ ê¸°ë°˜: id/key/uuid í¬í•¨)\n",
    "                        if any(keyword in col.lower() for keyword in ['id', 'key', 'uuid'])],\n",
    "        }\n",
    "        all_tables_info[name] = info                                          # í˜„ì¬ í…Œì´ë¸”ì˜ ìš”ì•½ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥(í›„ì† ì§‘ê³„/ë³´ê³ ìš©)\n",
    "        \n",
    "        print(f\"ğŸ“Š í¬ê¸°: {info['rows']:,}í–‰, {info['cols']}ì—´ ({info['memory_mb']:.1f}MB)\")   # í–‰/ì—´/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥(ì²œë‹¨ìœ„ êµ¬ë¶„ì í¬í•¨)\n",
    "        print(f\"ğŸ“ˆ ë°ì´í„° íƒ€ì…: ìˆ˜ì¹˜í˜• {info['numeric_cols']}ê°œ, ë²”ì£¼í˜• {info['categorical_cols']}ê°œ\")  # íƒ€ì… ê°œìˆ˜ ìš”ì•½\n",
    "        print(f\"âŒ ê²°ì¸¡ê°’: {info['missing_total']:,}ê°œ ({info['missing_rate']:.2%})\")         # ê²°ì¸¡ ì´í•©ê³¼ ì „ì²´ ë¹„ìœ¨ ì¶œë ¥\n",
    "        \n",
    "        if info['date_cols']:                                                 # ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´\n",
    "            print(f\"ğŸ“… ë‚ ì§œ ì»¬ëŸ¼: {info['date_cols']}\")                        # ëª©ë¡ ì¶œë ¥\n",
    "        if info['id_cols']:                                                   # ì‹ë³„ì ê´€ë ¨ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´\n",
    "            print(f\"ğŸ”‘ ID ì»¬ëŸ¼: {info['id_cols']}\")                           # ëª©ë¡ ì¶œë ¥\n",
    "        \n",
    "        # ì»¬ëŸ¼ ì •ë³´ \n",
    "        print(f\"\\nğŸ“‹ ì»¬ëŸ¼ ëª©ë¡ :\")                                             # ì»¬ëŸ¼ ìƒì„¸ ëª©ë¡ ì„¹ì…˜\n",
    "        for i, col in enumerate(df.columns[:], 1):                            # ëª¨ë“  ì»¬ëŸ¼ì„ ë²ˆí˜¸ì™€ í•¨ê»˜ ìˆœíšŒ\n",
    "            dtype = str(df[col].dtype)                                        # í•´ë‹¹ ì»¬ëŸ¼ì˜ dtype ë¬¸ìì—´\n",
    "            nunique = df[col].nunique()                                       # ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜\n",
    "            print(f\"  {i:2d}. {col:<25} ({dtype:<10}) - ìœ ë‹ˆí¬: {nunique:,}\") # ë²ˆí˜¸, ì»¬ëŸ¼ëª…(ì •ë ¬), dtype, ìœ ë‹ˆí¬ ê°œìˆ˜ ì¶œë ¥\n",
    "        \n",
    "        # ìƒ˜í”Œ ë°ì´í„°\n",
    "        print(f\"\\nğŸ“„ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3í–‰):\")                                  # ìƒ˜í”Œ ì¶œë ¥ ì„¹ì…˜ ì œëª©\n",
    "        print(df.head(3).to_string())                                         # ìƒìœ„ 3í–‰ì„ í‘œ í˜•íƒœë¡œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥(to_string)\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ ìƒì„¸\n",
    "        missing_info = df.isnull().sum()                                      # ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜\n",
    "        missing_info = missing_info[missing_info > 0].sort_values(ascending=False)  # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ë§Œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "        if not missing_info.empty:                                            # ê²°ì¸¡ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´\n",
    "            print(f\"\\nâš ï¸  ê²°ì¸¡ê°’ ìƒì„¸:\")                                         # ê²½ê³  ì•„ì´ì½˜ê³¼ í•¨ê»˜ ì„¹ì…˜ ì œëª©\n",
    "            for col, count in missing_info.head(5).items():                   # ê²°ì¸¡ ìƒìœ„ 5ê°œ ì»¬ëŸ¼ë§Œ ì¶œë ¥(ë„ˆë¬´ ë§ì„ ë•Œ ìš”ì•½)\n",
    "                rate = count / len(df) * 100                                  # í•´ë‹¹ ì»¬ëŸ¼ì˜ ê²°ì¸¡ë¥ (%)\n",
    "                print(f\"  {col:<25}: {count:,}ê°œ ({rate:.1f}%)\")              # ì»¬ëŸ¼ëª…, ê²°ì¸¡ ê°œìˆ˜, ê²°ì¸¡ë¥  í‘œì‹œ\n",
    "        else:\n",
    "            print(f\"\\nâœ… ê²°ì¸¡ê°’ ì—†ìŒ\")                                           # ê²°ì¸¡ì¹˜ê°€ ì „í˜€ ì—†ìŒì„ í‘œì‹œ\n",
    "        \n",
    "        # ========================================\n",
    "        # 3. ì €ì¹´ë””ë„ë¦¬í‹° ì»¬ëŸ¼ ë¶„ì„\n",
    "        # ========================================\n",
    "        print(f\"\\nğŸ·ï¸ 3. Low ì¹´ë””ë„ë¦¬í‹° ì»¬ëŸ¼ ë¶„ì„ (ìœ ë‹ˆí¬ â‰¤ {MAX_UNIQUE})\")     # ì €ì¹´ë””ë„ë¦¬í‹° ë¶„ì„ ì„¹ì…˜ ì œëª©\n",
    "        print(\"-\" * 50)                                                       # êµ¬ë¶„ì„ \n",
    "        \n",
    "        findings = []                                                          # ë°œê²¬ í•­ëª©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        for col in df.columns:                                                # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆœíšŒí•˜ë©´ì„œ\n",
    "            nunique = int(df[col].nunique(dropna=True))                       # NaN ì œì™¸ ìœ ë‹ˆí¬ ê°œìˆ˜ ê³„ì‚°\n",
    "            if nunique <= MAX_UNIQUE:                                         # ê¸°ì¤€ ì´í•˜(=ì €ì¹´ë””ë„ë¦¬í‹°)ë©´\n",
    "                vals = list(pd.Series(df[col].dropna().unique()).astype(\"string\"))  # ìœ ë‹ˆí¬ ê°’ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸í™”\n",
    "                try:\n",
    "                    vals = sorted(vals, key=lambda x: (x is None, str(x)))    # ì •ë ¬ ê°€ëŠ¥í•œ ê²½ìš° ì •ë ¬(ê°’/None ìˆœ)\n",
    "                except Exception:\n",
    "                    pass                                                       # ì •ë ¬ ì‹¤íŒ¨(ì„œë¡œ ë¹„êµ ë¶ˆê°€ íƒ€ì… í˜¼í•© ë“±) ì‹œ ê·¸ëƒ¥ í†µê³¼\n",
    "                preview = \", \".join([str(v) for v in vals[:MAX_UNIQUE]])      # ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸° ë¬¸ìì—´ë¡œ í•©ì¹¨\n",
    "                findings.append((col, str(df[col].dtype), nunique, preview))  # (ì»¬ëŸ¼ëª…, dtype, ìœ ë‹ˆí¬ ê°œìˆ˜, ê°’ ë¯¸ë¦¬ë³´ê¸°) íŠœí”Œ ì €ì¥\n",
    "        \n",
    "        if findings:                                                           # ë°œê²¬ëœ ì €ì¹´ë””ë„ë¦¬í‹° ì»¬ëŸ¼ì´ ìˆìœ¼ë©´\n",
    "            print(f\"ğŸ“Œ ì €ì¹´ë””ë„ë¦¬í‹° ì»¬ëŸ¼ ë°œê²¬:\")                                 # ì•ˆë‚´ ë¬¸êµ¬ ì¶œë ¥\n",
    "            for col, dtype_str, nunique, preview in findings:                 # ê° í•­ëª©ì„ ìˆœíšŒí•˜ë©°\n",
    "                print(f\"  {col:<25} ({dtype_str:<10}) nunique={nunique:2d} -> {preview}\")  # ìƒì„¸ ì •ë³´ ì¶œë ¥\n",
    "        else:\n",
    "            print(f\"âœ… ìœ ë‹ˆí¬ â‰¤ {MAX_UNIQUE}ì¸ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")                # í•´ë‹¹ ì—†ìŒ í‘œì‹œ\n",
    "        \n",
    "        # ========================================\n",
    "        # 4. ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ë¶„ì„\n",
    "        # ========================================\n",
    "        print(f\"\\nâš ï¸  4. ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ë¶„ì„\")                                 # ëˆ„ìˆ˜ ìœ„í—˜ ì„¹ì…˜ ì œëª©\n",
    "        print(\"-\" * 50)                                                       # êµ¬ë¶„ì„ \n",
    "        \n",
    "        risks = _analyze_data_leakage_risks(df, name)                         # ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë¡œ í˜„ì¬ í…Œì´ë¸”ì˜ ëˆ„ìˆ˜ ìœ„í—˜ í›„ë³´ í…ìŠ¤íŠ¸ ëª©ë¡ íšë“\n",
    "        data_leakage_risks[name] = risks                                      # ë”•ì…”ë„ˆë¦¬ì— ì €ì¥(í…Œì´ë¸”ëª…â†’ìœ„í—˜ëª©ë¡)\n",
    "        \n",
    "        if risks:                                                             # í•˜ë‚˜ë¼ë„ ìœ„í—˜ í›„ë³´ê°€ ìˆìœ¼ë©´\n",
    "            print(f\"ğŸš¨ ìœ„í—˜ ìš”ì†Œ ë°œê²¬:\")                                         # ê²½ê³  ì•„ì´ì½˜ ì¶œë ¥\n",
    "            for i, risk in enumerate(risks, 1):                               # ë²ˆí˜¸ì™€ í•¨ê»˜ ë‚˜ì—´\n",
    "                print(f\"  {i}. {risk}\")                                       # ê° ìœ„í—˜ ìš”ì†Œ ì„¤ëª… ì¶œë ¥\n",
    "        else:\n",
    "            print(f\"âœ… ìœ„í—˜ ìš”ì†Œ ì—†ìŒ\")                                          # ìœ„í—˜ ìš”ì†Œê°€ ì—†ìŒì„ í‘œì‹œ\n",
    "            \n",
    "    except Exception as e:                                                    # CSV ë¡œë“œë‚˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ\n",
    "        print(f\"\\nâŒ [{name}] ë¡œë“œ ì‹¤íŒ¨: {e}\")                                 # ì–´ë–¤ í…Œì´ë¸”ì—ì„œ ì‹¤íŒ¨í–ˆëŠ”ì§€ì™€ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52456dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict()\n",
    "\n",
    "# curated ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "args.default_data_path = \"./data/curated/\"\n",
    "args.player_final_file = \"player_final.csv\"\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(args.default_data_path + args.player_final_file)\n",
    "\n",
    "print(f\"âœ… player_final.csv ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape[0]:,}í–‰, {df.shape[1]}ì—´\")\n",
    "print(f\"ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
